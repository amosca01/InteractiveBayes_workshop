

Interaction is a core component of visualization design and a vital mode of communication between the user and visual system. In the visualization community, the study of interaction ranges from defining interaction~\cite{dimara2020What, yi2007Toward, heer2012Interactive}, to understanding the interplay between interaction and cognition~\cite{liu2010Mental, pohl2012User}, to leveraging user interactions to improve analytics~\cite{brown2012Disfunction, endert2012Semantic}. However, investigations into the value of adding interaction to a static design are rare and results are varied.
 
In some cases, the value-add of interaction to visualization is clear. In \textit{The Value of Visualization} van Wijk explains ``interaction is generally considered as good", and argues that it is invaluable to tasks such as allowing users to explore more data than can fit on a screen, and to customizing new visualization methods\cite{wijk2005Value}. Heer and Shneiderman echo this sentiment in their taxonomy of interactive dynamics for visual analysis\cite{heer2012Interactive}. 
Additionally, it has been argued that interaction is valuable due to its ability to amplify or illustrate user cognition\cite{yi2007Toward, pohl2012User, liu2010Mental}. A recent study by Zhi et al. found that adding interaction to a storytelling visualization increased 
%, but had no measurable impact on comprehension and recall
engagement~\cite{zhi2019linking}. Studies of multimedia instruction have shown that interactivity can increase deep learning and learning transfer~\cite{evans2007Interactivity, wang2011Impact}. 
      
However, the literature does not uniformly support interaction as an indisputable means of improving visualization. In fact, in \textit{The Value of Visualization} immediately after expressing the ``good" aspects of interaction van Wijk states that ``one could advocate the opposite: interaction should be avoided,'' and explains that interaction can negatively impact visualization by increasing subjectivity, and the user's perceptual and exploration costs~\cite{wijk2005Value}. Lam designed a framework that accounts for potential costs of interaction in information visualization, and encourages designers to weigh the cost against potential gains\cite{lam2008Framework}. A study by Theis et al.~\cite{theis2016Ergonomic} comparing task performance on interactive and static uncertainty visualizations found no significant difference in error rate between the two. And a study by Ragan et al.~\cite{ragan2012Spatial} comparing outcomes of a pictorial learning activity given an interactive or automatic view control found no significant differences between the two.       

In this paper, we investigate the following research question: ``What value can interaction add to a static visualization?'' We use a Bayesian reasoning task as a test bed for answering this question, because it is a well defined but difficult reasoning problem. 
%, with a clear-cut correct answer\cite{ottley2016Bayesian,micallef2012Assessing,khan2015Benefits}. In addition, 
%a static Bayesian reasoning visualization is a canonical example of visualization for communication. 
Moreover, Bayesian reasoning can be summarized quite succinctly by conditional probabilities and Bayes rule, however this often fails to communicate the real world situation represented by these numbers. As a result, there has been a plethora of research on communicating Bayesian reasoning through static visualization\cite{brase2009Pictorial, garcia2013Visual, kellenFacilitating2007, ottley2012Visually, tsai2011Interactive, friederichs2014Using, sedlmeier2001Teaching, spiegelhalter2011Visualizing, gigerenzer1995How, cole1989Understanding, cole1989Graphic, khan2018Interactive, bocherer2019How, ottley2016Bayesian, micallef2012Assessing, khan2015Benefits}. %, and several studies (with mixed findings) on communicating it through interactive visualization\cite{tsai2011Interactive, khan2018Interactive}.  

In addition to being an open problem area, communicating Bayesian reasoning is an ideal test bed for interaction because interaction is not imperative to the effectiveness of a Bayesian reasoning visualization like it is for most visual analytic systems, which are built to analyze large amounts of data. Static Bayesian reasoning visualizations typically do not represent more data than can fit on one screen. Thus, adding interaction does not add any otherwise obscured information to the visualization, it simply highlights or draws connections between information already present. This allows us to to isolate the value-add of interaction independent of data exploration and sensemaking. 

Moreover, prior studies on interactive Bayesian reasoning visualizations conclude with conflicting recommendations on interactivity\cite{tsai2011Interactive, khan2018Interactive}. We postulate that these differences could be due to differences in visualization design and individual user differences.
%It is well established that spatial ability plays a strong role in visualization use in general~\cite{liu2020Survey}, and especially on Bayesian reasoning\cite{ottley2016Bayesian}. Therefore, we postulate it must also play a role in the value-add of interaction of to a Bayesian reasoning visualization. 
In this work, we aim to gain a better understanding of how these two factors affect the value-add of interaction to a static Bayesian reasoning visualization. To this end, we run an Amazon Mechanical Turk study that investigates the effect of adding interactive checkboxes to three different static (or base) visualizations. The base visualizations range in their use of Gestalt principles to effectively depict sub-populations of interest in a Bayesian reasoning task. Analysis of the experiment shows that adding interaction to a static Bayesian reasoning visualization may not actually be beneficial to users.  
%does not necessarily lead to improvements in users' performance, and that users' spatial ability plays a strong role in the value-add of interaction.
In summary, we make the following contributions: 
\begin{enumerate}
	\item We demonstrate that adding interaction to a static Bayesian reasoning visualization can (under certain circumstances) \textit{impede} users' accuracy on a Bayesian reasoning task.  
	\item We show that adding interaction to a static Bayesian reasoning visualization tends not to affect the accuracy of people with low spatial ability, but in some cases can \textit{lower accuracy} of people with high spatial ability on a Bayesian reasoning task. 
\end{enumerate}

   
