\section{Discussion} 
Although it is a common belief that interactivity adds value to data visualization, scientific investigations into it merits can reveal essential insights about the pros, cons, or missed opportunities in visualization design. In this experiment, we used Bayesian reasoning -- a problem that is notoriously challenging for the general population -- and showed that interactivity can in some cases detract from reasoning accuracy. 

Our analyses suggest that the value of adding interactivity depends on the design of the visualization itself. We used three variations of icon arrays based on theories for how to facilitate Bayesian reasoning: \textit{grouped}, \textit{aligned}, and \textit{randomized}. We observed nearly identical accuracy between the interactive and static versions of the \textit{grouped} and \textit{aligned} designs, and a statistically significant decrease in accuracy for the \textit{randomized} design. One rationale for this outcome is that the combination of a challenging Bayesian problem with randomness and interactivity may have induced an extraneously high cognitive load. Interactivity has been linked to increased learning in the field of multimedia learning\cite{evans2007Interactivity}, but some experts caution that adding interactivity to a significantly complicated task can result in cognitive overload\cite{mayer2001Cognitive}. Our results may be an example of this phenomenon. Due to the lack of perceptual grouping, the \textit{randomized} base visualization induces more cognitive load than the \textit{grouped} and \textit{aligned} bases and adding interaction to it may have caused cognitive overload in participants.    

Stratified analyses show this trend holds for people with high spatial ability but not for people with low spatial ability. While it is well established that spatial ability affects visualization usage~\cite{liu2020Survey} and Bayesian reasoning~\cite{ottley2016Bayesian}, our finding is surprising.
Spatial ability is typically positively correlated with effective utilization of visualization~\cite{liu2020Survey}, however our finding indicates that the opposite can be true for some interactive visualizations. We reason that this may have occurred 
because our stimuli combines text and visualization. Integrating text and visualization for Bayesian reasoning has been shown to be more difficult for people with high spatial ability than for people with low spatial ability~\cite{ottley2016Bayesian}. The \textit{cbAll} interaction attempts to create an explicit link between text labels and the visualization, thus forcing users to integrate text and visualization. It may be the case that for people with high spatial ability the high cognitive load of the \textit{randomized} base coupled with the added cognitive load of integrating text and visualization because of the \textit{cbAll} interaction results in cognitive overload. Because people with low spatial ability struggle less to integrate textual and visual representations of Bayesian inference there may be less cognitive load added by the \textit{cbAll} interaction, thus explaining why we did not observe a similar decrease in performance for this group.  

%Ottley et al.~\cite{ottley2016Bayesian} found that participants with high spatial ability performed worse on a Bayesian reasoning problem when presented with textual \textit{and} visual representations problem than when presented with one of the two. They also found this was not the case for participants with low spatial ability~\cite{ottley2016Bayesian}. 
%Interactivity has been linked to increased learning in the field of multimedia learning\cite{evans2007Interactivity}, but some experts caution that adding interactivity to a significantly complicated task can result in cognitive overload\cite{mayer2001Cognitive}. Our results may be an example of this phenomenon. Due to the lack of perceptual grouping, the randomized base visualization requires more cognitive load than the grouped and aligned bases.  
%It may be the case that for people with high spatial ability the added cognitive load of the randomized base coupled with the added cognitive load of integrating textual and visual representations of Bayesian inference (which in this study we force with interaction) results in cognitive overload. Because people with low spatial ability struggle less to integrate textual and visual representations of Bayesian inference there may be less cognitive load added by an interaction that forces such an integration, thus explaining why we did not observe a decrease in performance given interactive randomized visualization for this group.  

%do people really interact?
An important observation is that a sizable portion of our study population ($30\%$) did not use the interactive components of the visualization. There are a combination of factors that can explain this result. %First, a user can accurately solve the problem without interacting with the checkboxes. In this instance, no interaction is equivalent to the static condition \remco{I would rework these three possibilities to just focus on 2 and 3 since you immediately dismiss the first possibility right after saying that it's possible}. 
No interaction could be indicative of participants who were either confused about the task or were simply clicking through to get paid, as discussed in Section \ref{sec:exp1_analysis}. 
%Further analysis suggests that the second rationale may be more plausible. We observed that the proportion of participants in this category who answered correctly was only 40\%.
Alternatively, it is possible that participants did not want to interact. Existing work indicates that people may not engage with interactive visualizations as much as previously thought~\cite{boy2015storytelling} and there have been reports of media venues such as \textit{The New York Times}, scaling back their creation of interactive visualization in lieu of static images\footnote{\label{foot:nyt}Why We Are Doing Fewer Interactives (Archie Tse, The New York Times): https://github.com/archietse/malofiej-2016/blob/master/tse-malofiej-2016-slides.pdf}.
While understanding if there is a value-add of interaction is an important step to user-centered interactive visualization design, we recognize that understanding users' perceived value of interaction is also crucial. We leave as future work investigating users' perceived value of interaction.  %\remco{love the ending of this. It gives me chills}

\section{Design Implications} 
Our findings suggest a nuanced answer to the question ``Does interaction improve Bayesian reasoning with visualizations?'' In this section, we present a few takeaways based on the results of our experiment.

\vspace{6pt} \noindent \textbf{Design Appropriately for Context}:
Our findings suggest that the cognitive load induced by a static visualization may effect whether adding interaction will detract from its effectiveness. We found that the accuracy of participants given base visualizations that leveraged perceptual grouping to reduce cognitive load (\textit{grouped}, \textit{aligned}) was generally unaffected by the addition of interaction. In contrast, the accuracy of participants given the \textit{randomized} base visualization, which did not use any perceptual grouping to reduce cognitive load, was significantly decreased by the addition of interaction (Figure \ref{fig:exp1_static_vs_int_by_base}). This suggests that in cases where a static visualization has a high amount of cognitive load, adding interaction will likely overload users and lead to poorer performance. However, in cases where a static visualization has a minimal amount of cognitive load designers can likely add interaction without overloading users. This can be particularly useful in cases where designers wish to leverage interaction for a purpose other than improving performance, for example, improving engagement.  

\vspace{6pt} \noindent \textbf{Interactions are Not Always Necessary}: Our findings suggest that a well-designed static visualization can be as beneficial (if not better) to solving complex reasoning tasks as interactive visualizations.
%It is important to note that 
In cases where the user's interactions result in additional information being shown on the visualization (e.g. panning a map), the value of the interaction is undisputed.
However, general claims that interaction can improve reasoning, and offer cognitive support can be called into question given the results of our experiment.
We observe that in multiple cases (such as when users have high spatial ability, or the underlying visualization induces high cognitive load), the use of an interactive visualization can be detrimental. However, this study only explored one interaction design, and there are innumerable ways interaction can be added to a static visualization. Future work testing different interaction designs is needed to before making any definitive claims about the value of adding interaction to a static visualization. Based on the results of this work, we echo the sentiment made by researchers such as Lam\cite{lam2008Framework} and van Wijk\cite{wijk2005Value}, and practitioners like the New York Times, and suggest a cautious use of interactivity in visualizations.

