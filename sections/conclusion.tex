\section{Conclusion} 
This paper aims to empirically show the how interaction may improve or detract from a static visualization. We use a classic Bayesian reasoning task as a test bed for evaluating interactive checkboxes across three different static visualization designs. Through a crowdsourced study we show the effect of interaction is largely dependent on the design of the underlying static visualization and users' spatial ability. 
Our work suggests that adding interaction to a static Bayesian reasoning visualization may not be beneficial. We find adding interactive checkboxes to a Bayesian reasoning visualization did not significantly increase performance on a Bayesian reasoning task, and some cases significantly detracted from it (for example with a cognitively taxing static visualization, particularly for users with high spatial ability). Our results point to the importance of developing good static visualizations, and weighing the cost of adding interaction against user needs and context. 





